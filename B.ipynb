{"cells":[{"cell_type":"code","execution_count":235,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Rauan\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>I thought this movie did a down right good job...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>I am a Catholic taught in parochial elementary...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>I'm going to have to disagree with the previou...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>No one expects the Star Trek movies to be high...</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                  review sentiment\n","0      One of the other reviewers has mentioned that ...  positive\n","1      A wonderful little production. <br /><br />The...  positive\n","2      I thought this was a wonderful way to spend ti...  positive\n","3      Basically there's a family where a little boy ...  negative\n","4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n","...                                                  ...       ...\n","49995  I thought this movie did a down right good job...  positive\n","49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n","49997  I am a Catholic taught in parochial elementary...  negative\n","49998  I'm going to have to disagree with the previou...  negative\n","49999  No one expects the Star Trek movies to be high...  negative\n","\n","[50000 rows x 2 columns]"]},"execution_count":235,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","import spacy\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn import metrics\n","nltk.download('stopwords')\n","\n","\n","# read the dataset using the compression zip\n","df = pd.read_csv('C:\\\\Users\\\\Rauan\\\\assignment-05-20Artee-1-main\\\\data\\\\archive.zip')\n","df"]},{"cell_type":"code","execution_count":236,"metadata":{},"outputs":[],"source":["nlp = spacy.load(\"en_core_web_sm\")\n","inputMeans=[]\n","for index, row in data.iterrows():\n","    inputMeans.append([])\n","    rowText = nlp(row['review'])\n","    for token in rowText:\n","        lineToken= nlp(token.text)\n","        vectorTokenized = lineToken[0].vector\n","        meanOfVector = vectorTokenized.mean()\n","        inputMeans[index].append(meanOfVector)\n"]},{"cell_type":"code","execution_count":237,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>349</th>\n","      <th>350</th>\n","      <th>351</th>\n","      <th>352</th>\n","      <th>353</th>\n","      <th>354</th>\n","      <th>355</th>\n","      <th>356</th>\n","      <th>357</th>\n","      <th>358</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.021577</td>\n","      <td>0.007362</td>\n","      <td>-0.012018</td>\n","      <td>-0.014315</td>\n","      <td>-0.008056</td>\n","      <td>0.003146</td>\n","      <td>-0.007447</td>\n","      <td>0.021139</td>\n","      <td>-0.009257</td>\n","      <td>0.001493</td>\n","      <td>...</td>\n","      <td>-0.012423</td>\n","      <td>0.044766</td>\n","      <td>-0.006958</td>\n","      <td>-0.015123</td>\n","      <td>-0.006147</td>\n","      <td>-0.003717</td>\n","      <td>-0.010683</td>\n","      <td>-0.012644</td>\n","      <td>-0.006645</td>\n","      <td>0.006869</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.016262</td>\n","      <td>-0.048202</td>\n","      <td>-0.021175</td>\n","      <td>-0.017137</td>\n","      <td>0.006869</td>\n","      <td>0.057338</td>\n","      <td>0.001860</td>\n","      <td>0.035583</td>\n","      <td>0.015235</td>\n","      <td>-0.028182</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.001160</td>\n","      <td>0.001980</td>\n","      <td>0.006571</td>\n","      <td>-0.015239</td>\n","      <td>-0.015828</td>\n","      <td>-0.048202</td>\n","      <td>-0.001316</td>\n","      <td>0.011616</td>\n","      <td>-0.009869</td>\n","      <td>0.001146</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.012464</td>\n","      <td>-0.013060</td>\n","      <td>0.005666</td>\n","      <td>-0.015828</td>\n","      <td>-0.024570</td>\n","      <td>0.043623</td>\n","      <td>-0.015828</td>\n","      <td>-0.021175</td>\n","      <td>0.013520</td>\n","      <td>0.013173</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.010133</td>\n","      <td>0.007558</td>\n","      <td>0.005666</td>\n","      <td>0.015053</td>\n","      <td>0.001768</td>\n","      <td>-0.015123</td>\n","      <td>-0.012018</td>\n","      <td>0.011427</td>\n","      <td>0.007362</td>\n","      <td>-0.003630</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.006760</td>\n","      <td>-0.007746</td>\n","      <td>0.027384</td>\n","      <td>0.063414</td>\n","      <td>0.001146</td>\n","      <td>-0.027599</td>\n","      <td>0.007841</td>\n","      <td>0.000681</td>\n","      <td>-0.015828</td>\n","      <td>-0.017751</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.001160</td>\n","      <td>-0.007471</td>\n","      <td>0.021080</td>\n","      <td>-0.046429</td>\n","      <td>0.011616</td>\n","      <td>-0.020933</td>\n","      <td>-0.015828</td>\n","      <td>-0.007327</td>\n","      <td>0.007362</td>\n","      <td>-0.015828</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.010849</td>\n","      <td>-0.015154</td>\n","      <td>-0.015239</td>\n","      <td>-0.010474</td>\n","      <td>-0.019292</td>\n","      <td>0.000681</td>\n","      <td>-0.034398</td>\n","      <td>0.070109</td>\n","      <td>-0.053979</td>\n","      <td>0.010384</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows Ã— 359 columns</p>\n","</div>"],"text/plain":["        0         1         2         3         4         5         6    \\\n","0  0.021577  0.007362 -0.012018 -0.014315 -0.008056  0.003146 -0.007447   \n","1  0.016262 -0.048202 -0.021175 -0.017137  0.006869  0.057338  0.001860   \n","2  0.001160  0.001980  0.006571 -0.015239 -0.015828 -0.048202 -0.001316   \n","3 -0.012464 -0.013060  0.005666 -0.015828 -0.024570  0.043623 -0.015828   \n","4  0.010133  0.007558  0.005666  0.015053  0.001768 -0.015123 -0.012018   \n","5  0.006760 -0.007746  0.027384  0.063414  0.001146 -0.027599  0.007841   \n","6  0.001160 -0.007471  0.021080 -0.046429  0.011616 -0.020933 -0.015828   \n","7  0.010849 -0.015154 -0.015239 -0.010474 -0.019292  0.000681 -0.034398   \n","\n","        7         8         9    ...       349       350       351       352  \\\n","0  0.021139 -0.009257  0.001493  ... -0.012423  0.044766 -0.006958 -0.015123   \n","1  0.035583  0.015235 -0.028182  ...       NaN       NaN       NaN       NaN   \n","2  0.011616 -0.009869  0.001146  ...       NaN       NaN       NaN       NaN   \n","3 -0.021175  0.013520  0.013173  ...       NaN       NaN       NaN       NaN   \n","4  0.011427  0.007362 -0.003630  ...       NaN       NaN       NaN       NaN   \n","5  0.000681 -0.015828 -0.017751  ...       NaN       NaN       NaN       NaN   \n","6 -0.007327  0.007362 -0.015828  ...       NaN       NaN       NaN       NaN   \n","7  0.070109 -0.053979  0.010384  ...       NaN       NaN       NaN       NaN   \n","\n","        353       354       355       356       357       358  \n","0 -0.006147 -0.003717 -0.010683 -0.012644 -0.006645  0.006869  \n","1       NaN       NaN       NaN       NaN       NaN       NaN  \n","2       NaN       NaN       NaN       NaN       NaN       NaN  \n","3       NaN       NaN       NaN       NaN       NaN       NaN  \n","4       NaN       NaN       NaN       NaN       NaN       NaN  \n","5       NaN       NaN       NaN       NaN       NaN       NaN  \n","6       NaN       NaN       NaN       NaN       NaN       NaN  \n","7       NaN       NaN       NaN       NaN       NaN       NaN  \n","\n","[8 rows x 359 columns]"]},"execution_count":237,"metadata":{},"output_type":"execute_result"}],"source":["x = pd.DataFrame(inputMeans)\n","x"]},{"cell_type":"code","execution_count":238,"metadata":{},"outputs":[],"source":["df.loc[df['sentiment'] == 'positive', 'sentiment'] = 1\n","df.loc[df['sentiment'] == 'negative', 'sentiment'] = 0\n"]},{"cell_type":"code","execution_count":239,"metadata":{},"outputs":[],"source":["\n","x = df['review']\n","y = df['sentiment']\n","y = y.astype('int')\n"]},{"cell_type":"code","execution_count":240,"metadata":{},"outputs":[],"source":["import spacy\n","nlp = spacy.load('en_core_web_sm')\n","\n","arr=[]\n","for i in range(len(x)):\n","    doc = nlp(x[i])\n","    arr.append(doc.vector)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [8, 0]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn [220], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m train_test_split(x, arr, test_size \u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m, random_state \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)\n","File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2445\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2442\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2443\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2445\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2447\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2448\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2449\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2450\u001b[0m )\n","File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:433\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \n\u001b[0;32m    416\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    432\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 433\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m result\n","File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [8, 0]"]}],"source":["\n","X_train, X_test, Y_train, Y_test = train_test_split(arr, y, test_size = 0.2, random_state = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","model = LogisticRegression()\n","model.fit(X_train, Y_train)\n","\n","prediction = model.predict(X_test)\n","accuracy_test = accuracy_score(Y_test, prediction)\n","print(accuracy_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'Y_test' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn [187], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(metrics\u001b[39m.\u001b[39mclassification_report(Y_test, prediction))\n","\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"]}],"source":["print(metrics.classification_report(Y_test, prediction))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"}}},"nbformat":4,"nbformat_minor":2}
